{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective: Predict if given the demographic, medical and behavioural information the person would have coronary heart disease in coming 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset:\n",
    "data_file = r'C:\\Users\\AnitaM\\Downloads\\framingham.csv'\n",
    "hd = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4238, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "hd_train, hd_test = train_test_split(hd, test_size=0.2, random_state=2, stratify=hd['TenYearCHD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3390, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(848, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NAs in train and test:\n",
    "\n",
    "hd_train['education'].fillna(hd_train['education'].median(), inplace=True)\n",
    "hd_train['cigsPerDay'].fillna(hd_train['cigsPerDay'].median(), inplace=True)\n",
    "hd_train['totChol'].fillna(hd_train['totChol'].median(), inplace=True)\n",
    "hd_train['BMI'].fillna(hd_train['BMI'].median(), inplace=True)\n",
    "hd_train['heartRate'].fillna(hd_train['heartRate'].median(), inplace=True)\n",
    "hd_train['glucose'].fillna(hd_train['glucose'].median(), inplace=True)\n",
    "\n",
    "hd_test['education'].fillna(hd_test['education'].median(), inplace=True)\n",
    "hd_test['cigsPerDay'].fillna(hd_test['cigsPerDay'].median(), inplace=True)\n",
    "hd_test['totChol'].fillna(hd_test['totChol'].median(), inplace=True)\n",
    "hd_test['BMI'].fillna(hd_test['BMI'].median(), inplace=True)\n",
    "hd_test['heartRate'].fillna(hd_test['heartRate'].median(), inplace=True)\n",
    "hd_test['glucose'].fillna(hd_test['glucose'].median(), inplace=True)\n",
    "\n",
    "# Droping BPMeds with NA values:\n",
    "hd_train.dropna(inplace=True)\n",
    "hd_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_train.reset_index(drop=True, inplace=True)\n",
    "hd_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_train = hd_train.drop('TenYearCHD', 1)\n",
    "y_train = hd_train['TenYearCHD']\n",
    "\n",
    "x_test = hd_test.drop('TenYearCHD', 1)\n",
    "y_test = hd_test['TenYearCHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data using Quantile Transformer due to the presence of outliers:\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "num_features = ['age', 'education', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
    "\n",
    "scaler.fit(x_train[num_features])\n",
    "scaled_train = scaler.transform(x_train[num_features])\n",
    "\n",
    "for i,col in enumerate(num_features):\n",
    "    x_train[col] = scaled_train[:,i]\n",
    "    \n",
    "scaled_test = scaler.transform(x_test[num_features])\n",
    "for i,col in enumerate(num_features):\n",
    "    x_test[col] = scaled_test[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.010382</td>\n",
       "      <td>0.864365</td>\n",
       "      <td>1</td>\n",
       "      <td>1.934489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.633317</td>\n",
       "      <td>-0.490721</td>\n",
       "      <td>-0.193143</td>\n",
       "      <td>0.157469</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>-1.242061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.365531</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.238089</td>\n",
       "      <td>-1.289578</td>\n",
       "      <td>-0.809168</td>\n",
       "      <td>0.312376</td>\n",
       "      <td>-2.196894</td>\n",
       "      <td>-0.590949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190587</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287442</td>\n",
       "      <td>-0.016310</td>\n",
       "      <td>-1.304121</td>\n",
       "      <td>0.568194</td>\n",
       "      <td>0.452858</td>\n",
       "      <td>-0.687939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.576075</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497809</td>\n",
       "      <td>0.032625</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>0.133166</td>\n",
       "      <td>1.571286</td>\n",
       "      <td>-0.687939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.147315</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.406079</td>\n",
       "      <td>0.144780</td>\n",
       "      <td>0.114415</td>\n",
       "      <td>0.291367</td>\n",
       "      <td>-1.228607</td>\n",
       "      <td>0.352151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male       age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0     1 -1.010382   0.864365              1    1.934489     0.0   \n",
       "1     1  0.365531   5.199338              0   -5.199338     0.0   \n",
       "2     1  0.190587  -5.199338              1    0.857097     0.0   \n",
       "3     0 -0.576075  -5.199338              1    0.035135     0.0   \n",
       "4     1  1.147315   5.199338              1    0.483658     0.0   \n",
       "\n",
       "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0                0             0         0 -0.633317 -0.490721 -0.193143   \n",
       "1                0             0         0 -0.238089 -1.289578 -0.809168   \n",
       "2                0             1         0  0.287442 -0.016310 -1.304121   \n",
       "3                0             0         0  0.497809  0.032625  0.374936   \n",
       "4                0             0         0 -0.406079  0.144780  0.114415   \n",
       "\n",
       "        BMI  heartRate   glucose  \n",
       "0  0.157469   0.015055 -1.242061  \n",
       "1  0.312376  -2.196894 -0.590949  \n",
       "2  0.568194   0.452858 -0.687939  \n",
       "3  0.133166   1.571286 -0.687939  \n",
       "4  0.291367  -1.228607  0.352151  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.644369</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720087</td>\n",
       "      <td>2.088211</td>\n",
       "      <td>-0.069056</td>\n",
       "      <td>-0.026349</td>\n",
       "      <td>1.446104</td>\n",
       "      <td>0.031369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.278302</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.071571</td>\n",
       "      <td>0.842694</td>\n",
       "      <td>0.853480</td>\n",
       "      <td>-0.085414</td>\n",
       "      <td>-0.462610</td>\n",
       "      <td>0.220058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.010382</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.529558</td>\n",
       "      <td>1.584354</td>\n",
       "      <td>-2.456904</td>\n",
       "      <td>0.670557</td>\n",
       "      <td>-0.462610</td>\n",
       "      <td>-0.373591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.540882</td>\n",
       "      <td>0.864365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.451469</td>\n",
       "      <td>-0.401995</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>0.776478</td>\n",
       "      <td>-0.354822</td>\n",
       "      <td>1.334066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.920412</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.644369</td>\n",
       "      <td>1.629992</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>2.495452</td>\n",
       "      <td>2.877846</td>\n",
       "      <td>0.651824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male       age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0     1  1.644369  -5.199338              1    0.483658     1.0   \n",
       "1     0  0.278302  -5.199338              0   -5.199338     1.0   \n",
       "2     1 -1.010382  -5.199338              0   -5.199338     0.0   \n",
       "3     1  0.540882   0.864365              1    0.483658     0.0   \n",
       "4     0  0.920412  -5.199338              1    0.358833     1.0   \n",
       "\n",
       "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0                0             1         0  0.720087  2.088211 -0.069056   \n",
       "1                0             1         0 -0.071571  0.842694  0.853480   \n",
       "2                0             1         0 -1.529558  1.584354 -2.456904   \n",
       "3                0             0         0 -0.451469 -0.401995 -0.025094   \n",
       "4                0             1         0  1.644369  1.629992  0.020074   \n",
       "\n",
       "        BMI  heartRate   glucose  \n",
       "0 -0.026349   1.446104  0.031369  \n",
       "1 -0.085414  -0.462610  0.220058  \n",
       "2  0.670557  -0.462610 -0.373591  \n",
       "3  0.776478  -0.354822  1.334066  \n",
       "4  2.495452   2.877846  0.651824  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling the values between 0,1 range using MinMaxScaler:\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "num_features = ['age', 'education', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
    "\n",
    "scaler.fit(x_train[num_features])\n",
    "scaled_train = scaler.transform(x_train[num_features])\n",
    "\n",
    "for i,col in enumerate(num_features):\n",
    "    x_train[col] = scaled_train[:,i]\n",
    "    \n",
    "scaled_test = scaler.transform(x_test[num_features])\n",
    "for i,col in enumerate(num_features):\n",
    "    x_test[col] = scaled_test[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.402836</td>\n",
       "      <td>0.583123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439096</td>\n",
       "      <td>0.452809</td>\n",
       "      <td>0.481426</td>\n",
       "      <td>0.515143</td>\n",
       "      <td>0.501448</td>\n",
       "      <td>0.380556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477104</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.422185</td>\n",
       "      <td>0.530040</td>\n",
       "      <td>0.288733</td>\n",
       "      <td>0.443171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.518328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527642</td>\n",
       "      <td>0.498432</td>\n",
       "      <td>0.374588</td>\n",
       "      <td>0.554641</td>\n",
       "      <td>0.543550</td>\n",
       "      <td>0.433844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.444601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547872</td>\n",
       "      <td>0.503137</td>\n",
       "      <td>0.536056</td>\n",
       "      <td>0.512806</td>\n",
       "      <td>0.651104</td>\n",
       "      <td>0.433844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.610333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460949</td>\n",
       "      <td>0.513923</td>\n",
       "      <td>0.511003</td>\n",
       "      <td>0.528020</td>\n",
       "      <td>0.381850</td>\n",
       "      <td>0.533865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male       age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0     1  0.402836   0.583123              1    0.686032     0.0   \n",
       "1     1  0.535152   1.000000              0    0.000000     0.0   \n",
       "2     1  0.518328   0.000000              1    0.582424     0.0   \n",
       "3     0  0.444601   0.000000              1    0.503379     0.0   \n",
       "4     1  0.610333   1.000000              1    0.546511     0.0   \n",
       "\n",
       "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0                0             0         0  0.439096  0.452809  0.481426   \n",
       "1                0             0         0  0.477104  0.375986  0.422185   \n",
       "2                0             1         0  0.527642  0.498432  0.374588   \n",
       "3                0             0         0  0.547872  0.503137  0.536056   \n",
       "4                0             0         0  0.460949  0.513923  0.511003   \n",
       "\n",
       "        BMI  heartRate   glucose  \n",
       "0  0.515143   0.501448  0.380556  \n",
       "1  0.530040   0.288733  0.443171  \n",
       "2  0.554641   0.543550  0.433844  \n",
       "3  0.512806   0.651104  0.433844  \n",
       "4  0.528020   0.381850  0.533865  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.658133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569248</td>\n",
       "      <td>0.700815</td>\n",
       "      <td>0.493359</td>\n",
       "      <td>0.497466</td>\n",
       "      <td>0.639066</td>\n",
       "      <td>0.503017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.526763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493117</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.582076</td>\n",
       "      <td>0.491786</td>\n",
       "      <td>0.455513</td>\n",
       "      <td>0.521162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.402836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352908</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.263729</td>\n",
       "      <td>0.564485</td>\n",
       "      <td>0.455513</td>\n",
       "      <td>0.464073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.552015</td>\n",
       "      <td>0.583123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456584</td>\n",
       "      <td>0.461342</td>\n",
       "      <td>0.497587</td>\n",
       "      <td>0.574671</td>\n",
       "      <td>0.465878</td>\n",
       "      <td>0.628292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.588512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.658133</td>\n",
       "      <td>0.656750</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>0.739978</td>\n",
       "      <td>0.776751</td>\n",
       "      <td>0.562683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male       age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0     1  0.658133   0.000000              1    0.546511     1.0   \n",
       "1     0  0.526763   0.000000              0    0.000000     1.0   \n",
       "2     1  0.402836   0.000000              0    0.000000     0.0   \n",
       "3     1  0.552015   0.583123              1    0.546511     0.0   \n",
       "4     0  0.588512   0.000000              1    0.534508     1.0   \n",
       "\n",
       "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0                0             1         0  0.569248  0.700815  0.493359   \n",
       "1                0             1         0  0.493117  0.581039  0.582076   \n",
       "2                0             1         0  0.352908  0.652361  0.263729   \n",
       "3                0             0         0  0.456584  0.461342  0.497587   \n",
       "4                0             1         0  0.658133  0.656750  0.501930   \n",
       "\n",
       "        BMI  heartRate   glucose  \n",
       "0  0.497466   0.639066  0.503017  \n",
       "1  0.491786   0.455513  0.521162  \n",
       "2  0.564485   0.455513  0.464073  \n",
       "3  0.574671   0.465878  0.628292  \n",
       "4  0.739978   0.776751  0.562683  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SMOTE to balance the imbalanced class:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "x_train_smote, y_train_smote = sm.fit_resample(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "f1  :  0.6747465035657454\n",
      "precision  :  0.6649774729409614\n",
      "recall  :  0.6852112676056338\n",
      "Decision Tree\n",
      "f1  :  0.8000923881125355\n",
      "precision  :  0.7891613440930965\n",
      "recall  :  0.8197183098591548\n",
      "Random Forest\n",
      "f1  :  0.9096671791191013\n",
      "precision  :  0.8977277774234512\n",
      "recall  :  0.9260563380281692\n",
      "XGB\n",
      "f1  :  0.8586159134279212\n",
      "precision  :  0.9181834929248518\n",
      "recall  :  0.8570422535211266\n",
      "SVM\n",
      "f1  :  0.6923238874498188\n",
      "precision  :  0.6794409752600974\n",
      "recall  :  0.7063380281690141\n",
      "KNN\n",
      "f1  :  0.8316573613150716\n",
      "precision  :  0.727773259682387\n",
      "recall  :  0.9704225352112676\n"
     ]
    }
   ],
   "source": [
    "# Performance of models when all the features are used:\n",
    "\n",
    "models = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), XGBClassifier(), \n",
    "          SVC(), KNeighborsClassifier()]\n",
    "\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGB', 'SVM', 'KNN']\n",
    "for model, name in zip(models, names):\n",
    "    print(name)\n",
    "    for score in [\"f1\", \"precision\", \"recall\"]:\n",
    "        print(score,\n",
    "              \" : \",\n",
    "              cross_val_score(model, x_train_smote, y_train_smote, scoring=score, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67      2840\n",
      "           1       0.67      0.69      0.68      2840\n",
      "\n",
      "    accuracy                           0.67      5680\n",
      "   macro avg       0.67      0.67      0.67      5680\n",
      "weighted avg       0.67      0.67      0.67      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78       712\n",
      "           1       0.28      0.71      0.40       127\n",
      "\n",
      "    accuracy                           0.68       839\n",
      "   macro avg       0.60      0.69      0.59       839\n",
      "weighted avg       0.83      0.68      0.72       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train_smote, y_train_smote)\n",
    "print(classification_report(y_train_smote, model.predict(x_train_smote)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  0.6821841092054604\n",
      "test :  0.5402160864345738\n"
     ]
    }
   ],
   "source": [
    "print('train : ', fbeta_score(y_train_smote, model.predict(x_train_smote), beta=2))\n",
    "print('test : ', fbeta_score(y_test, model.predict(x_test), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.81       712\n",
      "           1       0.22      0.39      0.28       127\n",
      "\n",
      "    accuracy                           0.70       839\n",
      "   macro avg       0.55      0.57      0.55       839\n",
      "weighted avg       0.78      0.70      0.73       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train_smote, y_train_smote)\n",
    "print(classification_report(y_train_smote, model.predict(x_train_smote)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  1.0\n",
      "test :  0.3401360544217687\n"
     ]
    }
   ],
   "source": [
    "print('train : ', fbeta_score(y_train_smote, model.predict(x_train_smote), beta=2))\n",
    "print('test : ', fbeta_score(y_test, model.predict(x_test), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       712\n",
      "           1       0.28      0.28      0.28       127\n",
      "\n",
      "    accuracy                           0.78       839\n",
      "   macro avg       0.57      0.57      0.57       839\n",
      "weighted avg       0.78      0.78      0.78       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train_smote, y_train_smote)\n",
    "print(classification_report(y_train_smote, model.predict(x_train_smote)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  1.0\n",
      "test :  0.2755905511811024\n"
     ]
    }
   ],
   "source": [
    "print('train : ', fbeta_score(y_train_smote, model.predict(x_train_smote), beta=2))\n",
    "print('test : ', fbeta_score(y_test, model.predict(x_test), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2840\n",
      "           1       1.00      0.98      0.99      2840\n",
      "\n",
      "    accuracy                           0.99      5680\n",
      "   macro avg       0.99      0.99      0.99      5680\n",
      "weighted avg       0.99      0.99      0.99      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       712\n",
      "           1       0.36      0.21      0.27       127\n",
      "\n",
      "    accuracy                           0.82       839\n",
      "   macro avg       0.61      0.57      0.58       839\n",
      "weighted avg       0.79      0.82      0.80       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(x_train_smote, y_train_smote)\n",
    "print(classification_report(y_train_smote, model.predict(x_train_smote)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  0.9871441689623508\n",
      "test :  0.23116438356164382\n"
     ]
    }
   ],
   "source": [
    "print('train : ', fbeta_score(y_train_smote, model.predict(x_train_smote), beta=2))\n",
    "print('test : ', fbeta_score(y_test, model.predict(x_test), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.84      2840\n",
      "           1       0.79      0.99      0.88      2840\n",
      "\n",
      "    accuracy                           0.86      5680\n",
      "   macro avg       0.89      0.86      0.86      5680\n",
      "weighted avg       0.89      0.86      0.86      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.66      0.75       712\n",
      "           1       0.21      0.51      0.30       127\n",
      "\n",
      "    accuracy                           0.63       839\n",
      "   macro avg       0.55      0.58      0.53       839\n",
      "weighted avg       0.78      0.63      0.68       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train_smote, y_train_smote)\n",
    "print(classification_report(y_train_smote, model.predict(x_train_smote)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  0.9443253383357899\n",
      "test :  0.39731051344743273\n"
     ]
    }
   ],
   "source": [
    "print('train : ', fbeta_score(y_train_smote, model.predict(x_train_smote), beta=2))\n",
    "print('test : ', fbeta_score(y_test, model.predict(x_test), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70      2840\n",
      "           1       0.69      0.72      0.71      2840\n",
      "\n",
      "    accuracy                           0.70      5680\n",
      "   macro avg       0.70      0.70      0.70      5680\n",
      "weighted avg       0.70      0.70      0.70      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77       712\n",
      "           1       0.26      0.66      0.37       127\n",
      "\n",
      "    accuracy                           0.66       839\n",
      "   macro avg       0.59      0.66      0.57       839\n",
      "weighted avg       0.82      0.66      0.71       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(x_train_smote, y_train_smote)\n",
    "print(classification_report(y_train_smote, model.predict(x_train_smote)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  0.7122367592527811\n",
      "test :  0.5035971223021584\n"
     ]
    }
   ],
   "source": [
    "print('train : ', fbeta_score(y_train_smote, model.predict(x_train_smote), beta=2))\n",
    "print('test : ', fbeta_score(y_test, model.predict(x_test), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65      2840\n",
      "           1       0.65      0.53      0.58      2840\n",
      "\n",
      "    accuracy                           0.62      5680\n",
      "   macro avg       0.62      0.62      0.61      5680\n",
      "weighted avg       0.62      0.62      0.61      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80       712\n",
      "           1       0.26      0.54      0.35       127\n",
      "\n",
      "    accuracy                           0.69       839\n",
      "   macro avg       0.58      0.63      0.57       839\n",
      "weighted avg       0.80      0.69      0.73       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train_smote, y_train_smote)\n",
    "print(classification_report(y_train_smote, model.predict(x_train_smote)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  0.5456008191325971\n",
      "test :  0.44401544401544407\n"
     ]
    }
   ],
   "source": [
    "print('train : ', fbeta_score(y_train_smote, model.predict(x_train_smote), beta=2))\n",
    "print('test : ', fbeta_score(y_test, model.predict(x_test), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1  :  0.9118445119862881\n",
      "precision  :  0.8942862836084912\n",
      "recall  :  0.9225352112676056\n"
     ]
    }
   ],
   "source": [
    "# Checking feature importance using a Random Forest Classification model and using those features to see if they improve performance:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "rf_sample = RandomForestClassifier()\n",
    "rf_sample.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "for score in ['f1', 'precision', 'recall']:\n",
    "    print(score,\n",
    "          ' : ',\n",
    "          cross_val_score(rf_sample, x_train_smote, y_train_smote, scoring=score, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa82cd3ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age             0.174653\n",
      "sysBP           0.117704\n",
      "diaBP           0.103302\n",
      "glucose         0.102878\n",
      "totChol         0.102038\n",
      "heartRate       0.097289\n",
      "BMI             0.093433\n",
      "cigsPerDay      0.069692\n",
      "education       0.068503\n",
      "prevalentHyp    0.025408\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feat_imp = pd.Series(rf_sample.feature_importances_, index=x_train_smote.columns)\n",
    "\n",
    "df_imp_feat = feat_imp.nlargest(10)\n",
    "\n",
    "df_imp_feat.plot(kind='barh')\n",
    "plt.show()\n",
    "print(df_imp_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feat_rf = ['age', 'sysBP', 'totChol', 'diaBP', 'glucose', 'heartRate', 'BMI', 'education',\n",
    "                                           'cigsPerDay', 'prevalentHyp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1  :  0.8999201882202585\n",
      "precision  :  0.8802577489941065\n",
      "recall  :  0.9161971830985914\n"
     ]
    }
   ],
   "source": [
    "# Using the above important features to build a random forest model to check its performance:\n",
    "rf_sample_imp_feat = RandomForestClassifier()\n",
    "for score in ['f1', 'precision', 'recall']:\n",
    "    print(score,\n",
    "          ' : ',\n",
    "          cross_val_score(rf_sample_imp_feat, x_train_smote[imp_feat_rf], y_train_smote, scoring=score, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      2840\n",
      "           1       0.66      0.67      0.67      2840\n",
      "\n",
      "    accuracy                           0.66      5680\n",
      "   macro avg       0.66      0.66      0.66      5680\n",
      "weighted avg       0.66      0.66      0.66      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.67      0.78       712\n",
      "           1       0.27      0.69      0.39       127\n",
      "\n",
      "    accuracy                           0.67       839\n",
      "   macro avg       0.60      0.68      0.58       839\n",
      "weighted avg       0.82      0.67      0.72       839\n",
      "\n",
      "Train score :  0.6706162798850173\n",
      "Test score :  0.5240963855421686\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       712\n",
      "           1       0.21      0.39      0.27       127\n",
      "\n",
      "    accuracy                           0.69       839\n",
      "   macro avg       0.54      0.56      0.54       839\n",
      "weighted avg       0.77      0.69      0.72       839\n",
      "\n",
      "Train score :  1.0\n",
      "Test score :  0.3310810810810811\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       712\n",
      "           1       0.28      0.28      0.28       127\n",
      "\n",
      "    accuracy                           0.78       839\n",
      "   macro avg       0.57      0.57      0.57       839\n",
      "weighted avg       0.78      0.78      0.78       839\n",
      "\n",
      "Train score :  1.0\n",
      "Test score :  0.2755905511811024\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2840\n",
      "           1       1.00      0.98      0.99      2840\n",
      "\n",
      "    accuracy                           0.99      5680\n",
      "   macro avg       0.99      0.99      0.99      5680\n",
      "weighted avg       0.99      0.99      0.99      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       712\n",
      "           1       0.23      0.14      0.17       127\n",
      "\n",
      "    accuracy                           0.80       839\n",
      "   macro avg       0.54      0.53      0.53       839\n",
      "weighted avg       0.76      0.80      0.78       839\n",
      "\n",
      "Train score :  0.9852286380662947\n",
      "Test score :  0.1530612244897959\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67      2840\n",
      "           1       0.67      0.74      0.71      2840\n",
      "\n",
      "    accuracy                           0.69      5680\n",
      "   macro avg       0.69      0.69      0.69      5680\n",
      "weighted avg       0.69      0.69      0.69      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75       712\n",
      "           1       0.23      0.60      0.33       127\n",
      "\n",
      "    accuracy                           0.64       839\n",
      "   macro avg       0.56      0.62      0.54       839\n",
      "weighted avg       0.80      0.64      0.69       839\n",
      "\n",
      "Train score :  0.7282323720160067\n",
      "Test score :  0.45292014302741357\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84      2840\n",
      "           1       0.79      0.99      0.88      2840\n",
      "\n",
      "    accuracy                           0.86      5680\n",
      "   macro avg       0.88      0.86      0.86      5680\n",
      "weighted avg       0.88      0.86      0.86      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.63      0.74       712\n",
      "           1       0.21      0.56      0.31       127\n",
      "\n",
      "    accuracy                           0.62       839\n",
      "   macro avg       0.55      0.60      0.52       839\n",
      "weighted avg       0.79      0.62      0.67       839\n",
      "\n",
      "Train score :  0.9380447901300791\n",
      "Test score :  0.42211652794292515\n",
      "NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.65      2840\n",
      "           1       0.65      0.51      0.57      2840\n",
      "\n",
      "    accuracy                           0.62      5680\n",
      "   macro avg       0.62      0.62      0.61      5680\n",
      "weighted avg       0.62      0.62      0.61      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81       712\n",
      "           1       0.26      0.52      0.35       127\n",
      "\n",
      "    accuracy                           0.70       839\n",
      "   macro avg       0.58      0.63      0.58       839\n",
      "weighted avg       0.80      0.70      0.74       839\n",
      "\n",
      "Train score :  0.5308269570335492\n",
      "Test score :  0.43363994743758216\n"
     ]
    }
   ],
   "source": [
    "# Performance of models when these selected features are used:\n",
    "\n",
    "models = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), XGBClassifier(), \n",
    "          SVC(), KNeighborsClassifier(), MultinomialNB()]\n",
    "\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGB', 'SVM', 'KNN', 'NB']\n",
    "for model, name in zip(models, names):\n",
    "    print(name)\n",
    "    model.fit(x_train_smote[imp_feat_rf], y_train_smote)\n",
    "    print(classification_report(y_train_smote, model.predict(x_train_smote[imp_feat_rf])))\n",
    "    print(classification_report(y_test, model.predict(x_test[imp_feat_rf])))\n",
    "    print('Train score : ', fbeta_score(y_train_smote, model.predict(x_train_smote[imp_feat_rf]), beta=2))\n",
    "    print('Test score : ', fbeta_score(y_test, model.predict(x_test[imp_feat_rf]), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature_Name       Score\n",
      "7    prevalentHyp  191.629032\n",
      "8        diabetes   40.475936\n",
      "0            male   37.574695\n",
      "5          BPMeds   27.509610\n",
      "2       education   16.724800\n",
      "1             age    9.302095\n",
      "10          sysBP    7.427628\n",
      "11          diaBP    3.507215\n",
      "4      cigsPerDay    1.956120\n",
      "3   currentSmoker    1.202418\n"
     ]
    }
   ],
   "source": [
    "# selecting 10 best features using Chi-squqred function:\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "best_features = SelectKBest(score_func=chi2, k=10)\n",
    "fit = best_features.fit(x_train_smote,y_train_smote)\n",
    "df_scores = pd.DataFrame(fit.scores_)\n",
    "df_columns = pd.DataFrame(x_train_smote.columns)\n",
    "\n",
    "# concatenate dataframes\n",
    "feature_scores = pd.concat([df_columns, df_scores],axis=1)\n",
    "feature_scores.columns = ['Feature_Name','Score']  # name output columns\n",
    "print(feature_scores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the above features to build models to check their performance:\n",
    "imp_feat_chi2 = ['prevalentHyp', 'diabetes', 'male', 'BPMeds', 'education', 'age', 'sysBP', \n",
    "                                             'diaBP', 'cigsPerDay', 'currentSmoker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67      2840\n",
      "           1       0.67      0.68      0.67      2840\n",
      "\n",
      "    accuracy                           0.67      5680\n",
      "   macro avg       0.67      0.67      0.67      5680\n",
      "weighted avg       0.67      0.67      0.67      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78       712\n",
      "           1       0.28      0.71      0.40       127\n",
      "\n",
      "    accuracy                           0.68       839\n",
      "   macro avg       0.60      0.69      0.59       839\n",
      "weighted avg       0.83      0.68      0.72       839\n",
      "\n",
      "Train score :  0.6786315199102636\n",
      "Test score :  0.5408653846153846\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       712\n",
      "           1       0.21      0.34      0.26       127\n",
      "\n",
      "    accuracy                           0.71       839\n",
      "   macro avg       0.54      0.56      0.54       839\n",
      "weighted avg       0.77      0.71      0.73       839\n",
      "\n",
      "Train score :  1.0\n",
      "Test score :  0.30239099859353025\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       712\n",
      "           1       0.27      0.32      0.29       127\n",
      "\n",
      "    accuracy                           0.77       839\n",
      "   macro avg       0.57      0.58      0.58       839\n",
      "weighted avg       0.78      0.77      0.77       839\n",
      "\n",
      "Train score :  1.0\n",
      "Test score :  0.31060606060606066\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.96      2840\n",
      "           1       1.00      0.93      0.96      2840\n",
      "\n",
      "    accuracy                           0.96      5680\n",
      "   macro avg       0.97      0.96      0.96      5680\n",
      "weighted avg       0.97      0.96      0.96      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       712\n",
      "           1       0.35      0.22      0.27       127\n",
      "\n",
      "    accuracy                           0.82       839\n",
      "   macro avg       0.61      0.57      0.58       839\n",
      "weighted avg       0.79      0.82      0.80       839\n",
      "\n",
      "Train score :  0.9434971819932939\n",
      "Test score :  0.23809523809523808\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68      2840\n",
      "           1       0.68      0.71      0.70      2840\n",
      "\n",
      "    accuracy                           0.69      5680\n",
      "   macro avg       0.69      0.69      0.69      5680\n",
      "weighted avg       0.69      0.69      0.69      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       712\n",
      "           1       0.25      0.66      0.37       127\n",
      "\n",
      "    accuracy                           0.66       839\n",
      "   macro avg       0.59      0.66      0.57       839\n",
      "weighted avg       0.82      0.66      0.70       839\n",
      "\n",
      "Train score :  0.706124155228872\n",
      "Test score :  0.5011933174224343\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.84      2840\n",
      "           1       0.80      0.95      0.87      2840\n",
      "\n",
      "    accuracy                           0.86      5680\n",
      "   macro avg       0.87      0.86      0.86      5680\n",
      "weighted avg       0.87      0.86      0.86      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76       712\n",
      "           1       0.22      0.52      0.31       127\n",
      "\n",
      "    accuracy                           0.65       839\n",
      "   macro avg       0.55      0.59      0.53       839\n",
      "weighted avg       0.79      0.65      0.69       839\n",
      "\n",
      "Train score :  0.9161290322580644\n",
      "Test score :  0.40740740740740744\n",
      "NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64      2840\n",
      "           1       0.63      0.54      0.58      2840\n",
      "\n",
      "    accuracy                           0.61      5680\n",
      "   macro avg       0.61      0.61      0.61      5680\n",
      "weighted avg       0.61      0.61      0.61      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.77       712\n",
      "           1       0.24      0.58      0.34       127\n",
      "\n",
      "    accuracy                           0.66       839\n",
      "   macro avg       0.57      0.63      0.56       839\n",
      "weighted avg       0.80      0.66      0.71       839\n",
      "\n",
      "Train score :  0.5527747551686616\n",
      "Test score :  0.4556650246305418\n"
     ]
    }
   ],
   "source": [
    "# Performance of models when these selected features are used:\n",
    "\n",
    "models = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), XGBClassifier(), \n",
    "          SVC(), KNeighborsClassifier(), MultinomialNB()]\n",
    "\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGB', 'SVM', 'KNN', 'NB']\n",
    "for model, name in zip(models, names):\n",
    "    print(name)\n",
    "    model.fit(x_train_smote[imp_feat_chi2], y_train_smote)\n",
    "    print(classification_report(y_train_smote, model.predict(x_train_smote[imp_feat_chi2])))\n",
    "    print(classification_report(y_test, model.predict(x_test[imp_feat_chi2])))\n",
    "    print('Train score : ', fbeta_score(y_train_smote, model.predict(x_train_smote[imp_feat_chi2]), beta=2))\n",
    "    print('Test score : ', fbeta_score(y_test, model.predict(x_test[imp_feat_chi2]), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature_Name       Score\n",
      "1            age  641.512915\n",
      "10         sysBP  442.445565\n",
      "7   prevalentHyp  334.135655\n",
      "11         diaBP  199.565857\n",
      "0           male   70.682259\n",
      "12           BMI   56.237554\n",
      "14       glucose   52.709303\n",
      "9        totChol   51.894149\n",
      "2      education   51.409176\n",
      "8       diabetes   42.149720\n"
     ]
    }
   ],
   "source": [
    "# selecting 10 best features using f_classif function:\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "best_features = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = best_features.fit(x_train_smote,y_train_smote)\n",
    "df_scores = pd.DataFrame(fit.scores_)\n",
    "df_columns = pd.DataFrame(x_train_smote.columns)\n",
    "\n",
    "# concatenate dataframes\n",
    "feature_scores = pd.concat([df_columns, df_scores],axis=1)\n",
    "feature_scores.columns = ['Feature_Name','Score']  # name output columns\n",
    "print(feature_scores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the above features to build models to check their performance:\n",
    "imp_feat_fclassif = ['age', 'sysBP', 'prevalentHyp', 'diaBP', 'male', 'BMI', 'glucose', \n",
    "                                             'totChol', 'education', 'diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66      2840\n",
      "           1       0.66      0.69      0.68      2840\n",
      "\n",
      "    accuracy                           0.67      5680\n",
      "   macro avg       0.67      0.67      0.67      5680\n",
      "weighted avg       0.67      0.67      0.67      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.65      0.77       712\n",
      "           1       0.27      0.73      0.40       127\n",
      "\n",
      "    accuracy                           0.66       839\n",
      "   macro avg       0.60      0.69      0.58       839\n",
      "weighted avg       0.83      0.66      0.71       839\n",
      "\n",
      "Train score :  0.6831212417843657\n",
      "Test score :  0.5477031802120141\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       712\n",
      "           1       0.21      0.33      0.26       127\n",
      "\n",
      "    accuracy                           0.71       839\n",
      "   macro avg       0.54      0.56      0.54       839\n",
      "weighted avg       0.77      0.71      0.74       839\n",
      "\n",
      "Train score :  1.0\n",
      "Test score :  0.29702970297029707\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2840\n",
      "           1       1.00      1.00      1.00      2840\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       712\n",
      "           1       0.30      0.35      0.32       127\n",
      "\n",
      "    accuracy                           0.78       839\n",
      "   macro avg       0.59      0.60      0.59       839\n",
      "weighted avg       0.79      0.78      0.78       839\n",
      "\n",
      "Train score :  1.0\n",
      "Test score :  0.33536585365853655\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      2840\n",
      "           1       1.00      0.97      0.99      2840\n",
      "\n",
      "    accuracy                           0.99      5680\n",
      "   macro avg       0.99      0.99      0.99      5680\n",
      "weighted avg       0.99      0.99      0.99      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       712\n",
      "           1       0.33      0.20      0.25       127\n",
      "\n",
      "    accuracy                           0.82       839\n",
      "   macro avg       0.60      0.57      0.57       839\n",
      "weighted avg       0.79      0.82      0.80       839\n",
      "\n",
      "Train score :  0.9770603228547153\n",
      "Test score :  0.22146507666098808\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68      2840\n",
      "           1       0.68      0.69      0.69      2840\n",
      "\n",
      "    accuracy                           0.68      5680\n",
      "   macro avg       0.68      0.68      0.68      5680\n",
      "weighted avg       0.68      0.68      0.68      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.66      0.77       712\n",
      "           1       0.27      0.70      0.39       127\n",
      "\n",
      "    accuracy                           0.67       839\n",
      "   macro avg       0.60      0.68      0.58       839\n",
      "weighted avg       0.83      0.67      0.71       839\n",
      "\n",
      "Train score :  0.6915042759007431\n",
      "Test score :  0.5303933253873659\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.84      2840\n",
      "           1       0.79      0.97      0.87      2840\n",
      "\n",
      "    accuracy                           0.86      5680\n",
      "   macro avg       0.88      0.86      0.86      5680\n",
      "weighted avg       0.88      0.86      0.86      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.62      0.73       712\n",
      "           1       0.22      0.62      0.33       127\n",
      "\n",
      "    accuracy                           0.62       839\n",
      "   macro avg       0.56      0.62      0.53       839\n",
      "weighted avg       0.80      0.62      0.67       839\n",
      "\n",
      "Train score :  0.931986531986532\n",
      "Test score :  0.4593023255813953\n",
      "NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65      2840\n",
      "           1       0.65      0.53      0.58      2840\n",
      "\n",
      "    accuracy                           0.62      5680\n",
      "   macro avg       0.62      0.62      0.62      5680\n",
      "weighted avg       0.62      0.62      0.62      5680\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80       712\n",
      "           1       0.26      0.54      0.35       127\n",
      "\n",
      "    accuracy                           0.69       839\n",
      "   macro avg       0.58      0.63      0.57       839\n",
      "weighted avg       0.80      0.69      0.73       839\n",
      "\n",
      "Train score :  0.5462922334357173\n",
      "Test score :  0.44458762886597947\n"
     ]
    }
   ],
   "source": [
    "# Performance of models when these selected features are used:\n",
    "\n",
    "models = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), XGBClassifier(), \n",
    "          SVC(), KNeighborsClassifier(), MultinomialNB()]\n",
    "\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGB', 'SVM', 'KNN', 'NB']\n",
    "for model, name in zip(models, names):\n",
    "    print(name)\n",
    "    model.fit(x_train_smote[imp_feat_fclassif], y_train_smote)\n",
    "    print(classification_report(y_train_smote, model.predict(x_train_smote[imp_feat_fclassif])))\n",
    "    print(classification_report(y_test, model.predict(x_test[imp_feat_fclassif])))\n",
    "    print('Train score : ', fbeta_score(y_train_smote, model.predict(x_train_smote[imp_feat_fclassif]), beta=2))\n",
    "    print('Test score : ', fbeta_score(y_test, model.predict(x_test[imp_feat_fclassif]), beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper tuning LR model with all parameters and NB model with selected parameters from Chi2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lr = {'penalty' : ['l1','l2'],\n",
    "          'C' : np.linspace(0.01,10,1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(LogisticRegression(random_state=2),\n",
    "                           param_grid=param_lr,\n",
    "                           cv=10,\n",
    "                           scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=2),\n",
       "             param_grid={'C': array([ 0.01,  0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,  0.09,\n",
       "        0.1 ,  0.11,  0.12,  0.13,  0.14,  0.15,  0.16,  0.17,  0.18,\n",
       "        0.19,  0.2 ,  0.21,  0.22,  0.23,  0.24,  0.25,  0.26,  0.27,\n",
       "        0.28,  0.29,  0.3 ,  0.31,  0.32,  0.33,  0.34,  0.35,  0.36,\n",
       "        0.37,  0.38,  0.39,  0.4 ,  0.41,  0.42,  0.43,  0.44,  0.45,\n",
       "        0.46,  0.47,  0.48,  0.49,  0.5 ,  0.51,  0.52,  0.53,  0.5...\n",
       "        9.37,  9.38,  9.39,  9.4 ,  9.41,  9.42,  9.43,  9.44,  9.45,\n",
       "        9.46,  9.47,  9.48,  9.49,  9.5 ,  9.51,  9.52,  9.53,  9.54,\n",
       "        9.55,  9.56,  9.57,  9.58,  9.59,  9.6 ,  9.61,  9.62,  9.63,\n",
       "        9.64,  9.65,  9.66,  9.67,  9.68,  9.69,  9.7 ,  9.71,  9.72,\n",
       "        9.73,  9.74,  9.75,  9.76,  9.77,  9.78,  9.79,  9.8 ,  9.81,\n",
       "        9.82,  9.83,  9.84,  9.85,  9.86,  9.87,  9.88,  9.89,  9.9 ,\n",
       "        9.91,  9.92,  9.93,  9.94,  9.95,  9.96,  9.97,  9.98,  9.99,\n",
       "       10.  ]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78       712\n",
      "           1       0.28      0.71      0.40       127\n",
      "\n",
      "    accuracy                           0.68       839\n",
      "   macro avg       0.60      0.69      0.59       839\n",
      "weighted avg       0.83      0.68      0.72       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67      2840\n",
      "           1       0.67      0.69      0.68      2840\n",
      "\n",
      "    accuracy                           0.67      5680\n",
      "   macro avg       0.67      0.67      0.67      5680\n",
      "weighted avg       0.67      0.67      0.67      5680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_smote, lr_model.predict(x_train_smote)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5415162454873647"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, lr_model.predict(x_test), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6839012103827049"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_train_smote, lr_model.predict(x_train_smote), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_nb = {'alpha' : np.linspace(0.01,10,100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(MultinomialNB(), n_iter=60,\n",
    "                                   cv=10,\n",
    "                                   scoring='recall',\n",
    "                                   random_state=2,\n",
    "                                   param_distributions=param_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=MultinomialNB(), n_iter=60,\n",
       "                   param_distributions={'alpha': array([ 0.01      ,  0.11090909,  0.21181818,  0.31272727,  0.41363636,\n",
       "        0.51454545,  0.61545455,  0.71636364,  0.81727273,  0.91818182,\n",
       "        1.01909091,  1.12      ,  1.22090909,  1.32181818,  1.42272727,\n",
       "        1.52363636,  1.62454545,  1.72545455,  1.82636364,  1.92727273,\n",
       "        2.02818182,  2.12909091,  2.23      ,  2.33090909,  2.43181...\n",
       "        6.56909091,  6.67      ,  6.77090909,  6.87181818,  6.97272727,\n",
       "        7.07363636,  7.17454545,  7.27545455,  7.37636364,  7.47727273,\n",
       "        7.57818182,  7.67909091,  7.78      ,  7.88090909,  7.98181818,\n",
       "        8.08272727,  8.18363636,  8.28454545,  8.38545455,  8.48636364,\n",
       "        8.58727273,  8.68818182,  8.78909091,  8.89      ,  8.99090909,\n",
       "        9.09181818,  9.19272727,  9.29363636,  9.39454545,  9.49545455,\n",
       "        9.59636364,  9.69727273,  9.79818182,  9.89909091, 10.        ])},\n",
       "                   random_state=2, scoring='recall')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train_smote[imp_feat_chi2], y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.77       712\n",
      "           1       0.24      0.58      0.34       127\n",
      "\n",
      "    accuracy                           0.66       839\n",
      "   macro avg       0.57      0.63      0.56       839\n",
      "weighted avg       0.80      0.66      0.71       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, mnb_model.predict(x_test[imp_feat_chi2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64      2840\n",
      "           1       0.63      0.54      0.58      2840\n",
      "\n",
      "    accuracy                           0.61      5680\n",
      "   macro avg       0.61      0.61      0.61      5680\n",
      "weighted avg       0.61      0.61      0.61      5680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_smote, mnb_model.predict(x_train_smote[imp_feat_chi2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4556650246305418"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, mnb_model.predict(x_test[imp_feat_chi2]), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5527747551686616"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_train_smote, mnb_model.predict(x_train_smote[imp_feat_chi2]), beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Multinomial bayes model\n",
    "import pickle\n",
    "\n",
    "# open a file, where you ant to store the data\n",
    "file = open('Heart_DiseasePred.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(mnb_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
